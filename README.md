<p align="center">
  <a href="https://swebench.com">
    <img src="assets/figures/vayavya-logo.svg" style="height: 10em" alt="vayavya-logo" />
  </a>
</p>



---

# SWE-bench-c

Test framework for bench marking ability of LM's to solve real world problems(specifically for c/c++).

# Data sets

These are the repositories used in c bench marking
| repo | homepage | License |
| ------| -------------- | ---------------|
| zstd | https://github.com/facebook/zstd | GPL-2.0 |
| jq   | https://github.com/jqlang/jq | jq-custom |
| redis | https://github.com/redis/redis | RSALv2 |


# Set up

`Python` and `docker` are required to run the *SWE-bench-c* and at least *8 cores* and *16 GB RAM* is recommended for running.
SWE-bench-c will also generate lot of docker images during running. Even though they are removed once the test finishes
you are recommended to have at least 150GB storage in your root partition or wherever the docker stores the images

> [!NOTE]
> This is not tested on MacOS or Windows, but it should work as long as you have python and docker setup.
> Feel free to give it a try and raise issue if you found any problem

First clone the repo and install the dependencies
```bash
git clone https://github.com/SWE-bench-c/SWE-bench-c.git
cd SWE-bench-c
# below 2 steps are optional
virtualenv .venv
source .venv/bin/activate

# install dependencies
pip install -e .
```

Test your installation by running
```bash
python -m swebench.harness.run_evaluation \
    --predictions_path gold \
    --max_workers 1 \
    --instance_ids jqlang__jq-3179 \
    --run_id validate-gold
```

This will generate report `gold.validate-gold.json`. Where you should see `jqlang__jq-3179` in `resolved` section

# Usage

To evaluate a patch set run the below command:

```bash
python -m swebench.harness.run_evaluation \
    --dataset_name SWE-bench-c/SWE-bench-c \
    --predictions_path <path_to_predictions> \
    --max_workers <num_workers> \
    --run_id <run_id>
```
Where
    - `dataset_name` is collection of PR's and issue tickets and test patches(This is now taking from hugging face)
    - `predictions_path` is solutions generated by the model. Use `gold` to run actual solution patch, this will also be stored in hugging face
    - `max_workers` Optional parameter which should be ~(number of cores on the machine) for faster execution or 1 for running on single core
    - `run_id` is a unique string to distinguish between subsequent runs.

To add/generate more tests follow this guide.
To generate patch set from models use this guide.

### Inspiration

This code is forked from [swebench](https://github.com/SWE-bench/SWE-bench) with special modifications to work with c/c++ repositories

## ðŸªª License
MIT. Check `LICENSE.md`.
